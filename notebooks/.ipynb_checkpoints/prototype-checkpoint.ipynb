{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVpLts8-I_qP"
   },
   "source": [
    "# Prototype for a chatbot\n",
    "\n",
    "Use this notebook if you want to experiment\n",
    "\n",
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4NQTAUxxAyr"
   },
   "source": [
    "# Smart searcher Bot ( a feature to be added later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9on93oPVxC2u"
   },
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "query = 'how old is samuel l jackson'\n",
    "\n",
    "## Google Search query results as a Python List of URLs\n",
    "search_result_list = list(search(query, tld=\"co.in\", num=10, stop=3, pause=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iED9GDE2xHNX"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from googlesearch import search\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "query = 'how old is samuel l jackson'\n",
    "\n",
    "## Google Search query results as a Python List of URLs\n",
    "search_result_list = list(search(query, tld=\"co.in\", num=10, stop=3, pause=1))\n",
    "\n",
    "page = requests.get(search_result_list[0])\n",
    "\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "soup = BeautifulSoup(page.content, features=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Q55egL5txNkW",
    "outputId": "b3f2e06b-591c-4d66-bb6b-f71431f18370"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Dear visitor, if you know the answer to this question, please post it'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import string\n",
    "from lxml import html\n",
    "from googlesearch import search\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# to search\n",
    "# print(chatbot_query('how old is samuel l jackson'))\n",
    "\n",
    "def chatbot_query(query, index=0):\n",
    "    fallback = 'Sorry, I cannot think of a reply for that.'\n",
    "    result = ''\n",
    "\n",
    "    try:\n",
    "        search_result_list = list(search(query, tld=\"co.in\", num=10, stop=3, pause=1))\n",
    "\n",
    "        page = requests.get(search_result_list[index])\n",
    "\n",
    "        tree = html.fromstring(page.content)\n",
    "\n",
    "        soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "\n",
    "        article_text = ''\n",
    "        article = soup.findAll('p')\n",
    "        for element in article:\n",
    "            article_text += '\\n' + ''.join(element.findAll(text = True))\n",
    "        article_text = article_text.replace('\\n', '')\n",
    "        first_sentence = article_text.split('.')\n",
    "        first_sentence = first_sentence[0].split('?')[0]\n",
    "\n",
    "        chars_without_whitespace = first_sentence.translate(\n",
    "            { ord(c): None for c in string.whitespace }\n",
    "        )\n",
    "\n",
    "        if len(chars_without_whitespace) > 0:\n",
    "            result = first_sentence\n",
    "        else:\n",
    "            result = fallback\n",
    "\n",
    "        return result\n",
    "    except:\n",
    "        if len(result) == 0: result = fallback\n",
    "        return result\n",
    "\n",
    "query = 'shimatta'\n",
    "chatbot_query(query, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3MWhLO8xoS-"
   },
   "outputs": [],
   "source": [
    "#https://github.com/lmzach09/Python_ChatBot_Google/blob/master/google_search.py\n",
    "#https://towardsdatascience.com/build-a-simple-chatbot-with-python-and-google-search-c000aa3f73f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3vOuWrwyLjq"
   },
   "outputs": [],
   "source": [
    "#https://heartbeat.fritz.ai/building-a-conversational-chatbot-with-nltk-and-tensorflow-part-1-f452ce1756e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUFihYam5F5a"
   },
   "source": [
    "# First demo\n",
    "https://heartbeat.fritz.ai/building-a-conversational-chatbot-with-nltk-and-tensorflow-part-1-f452ce1756e5\n",
    "\n",
    "https://towardsdatascience.com/build-it-yourself-chatbot-api-with-keras-tensorflow-model-f6d75ce957a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_4vvAUd5iqn"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pDUJPwz9lRC",
    "outputId": "be17128d-9029-4f09-e419-4b0147862baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiCMWo5O5UZA"
   },
   "outputs": [],
   "source": [
    "file = open('/content/intents1.json','r')\n",
    "intents = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffskzwyaJ3g_",
    "outputId": "35a870b2-862d-49b4-d004-fec196652466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'context_set': '',\n",
       "   'patterns': ['Hi',\n",
       "    'How are you',\n",
       "    'Is anyone there?',\n",
       "    'Hello',\n",
       "    'Hey',\n",
       "    'Good day',\n",
       "    'Whats up'],\n",
       "   'responses': ['Hello!',\n",
       "    'Good to see you again!',\n",
       "    'Hi there, how can I help?'],\n",
       "   'tag': 'greeting'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['cya',\n",
       "    'See you later',\n",
       "    'Goodbye',\n",
       "    'I am Leaving',\n",
       "    'Have a Good day',\n",
       "    'bye'],\n",
       "   'responses': ['Sad to see you go..', 'Talk to you later', 'Goodbye!'],\n",
       "   'tag': 'goodbye'},\n",
       "  {'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n",
       "   'responses': ['Happy to help!', 'Any time!', 'My pleasure'],\n",
       "   'tag': 'thanks'},\n",
       "  {'patterns': ['What hours are you open?',\n",
       "    'What are your hours?',\n",
       "    'When are you open?'],\n",
       "   'responses': [\"We're always active!\",\n",
       "    'We try our best toe be always active.'],\n",
       "   'tag': 'hours'},\n",
       "  {'context': [''],\n",
       "   'patterns': [],\n",
       "   'responses': [\"Sorry, can't understand you\",\n",
       "    'Please give me more info',\n",
       "    'Not sure I understand'],\n",
       "   'tag': 'noanswer'},\n",
       "  {'context': [''],\n",
       "   'patterns': ['How you could help me?',\n",
       "    'What you can do?',\n",
       "    'What help you provide?',\n",
       "    'How you can be helpful?',\n",
       "    'What support is offered'],\n",
       "   'responses': ['I can guide you through the ENICarthage Press Discord Server.',\n",
       "    'I can help you with anything related to ENICarthage Press.'],\n",
       "   'tag': 'options'},\n",
       "  {'context': [''],\n",
       "   'patterns': ['What is Enicarthage Press?',\n",
       "    'Can you please introduce me to ENICarthage Press?',\n",
       "    'What is Enicar press?',\n",
       "    'Tell me about this club.',\n",
       "    'Present Enicar press to me.',\n",
       "    'I need to know what this club is about.'],\n",
       "   'responses': ['It began first as an idea, then it blossomed into something beautiful. Far beyond any ordinary club.',\n",
       "    'Enicarthage Press is apparently a club for media, journalism, writing and arts but fundamentally a club for every future engineer to unleash their potential by nurturing their motivation and guiding their curiosity.',\n",
       "    'Some would argue that a Press club would not fit engineers. But this opinion is wrong indeed. Engineers must communicate, speak, explain and argue as best as they can. Engineers should empower their creativity in order to grasp success in the future.'],\n",
       "   'tag': 'present'},\n",
       "  {'context': [''],\n",
       "   'patterns': ['What is the objective of the club?',\n",
       "    'What is your objective?',\n",
       "    'Do you have a goal?',\n",
       "    'What is your mission?'],\n",
       "   'responses': ['Covering everything with dynamism and benevolence in order to propagate a high quality content , remains Press ENICarthageâ€™s success generator.',\n",
       "    'Getting out of grids And pushing Press participants to discover the hidden potentials is ,indeed, Press ENICarthageâ€™s framework .',\n",
       "    'Because it is an inspirational club, the relational and motivational component is and will always be its main target.'],\n",
       "   'tag': 'mission'},\n",
       "  {'context': [''],\n",
       "   'patterns': ['What do you do?',\n",
       "    'What are the activites of ENICarthage Press?',\n",
       "    'Tell me about your activites?',\n",
       "    'How can the club be helpful to me?',\n",
       "    'What activities are offered'],\n",
       "   'responses': ['We have Writing, Podcasts, Graphic Design, Debates, Presentations, courses and even playing games like Among Us!'],\n",
       "   'tag': 'activities'},\n",
       "  {'context': [''],\n",
       "   'patterns': ['How did this club come to be?',\n",
       "    'Tell me about the history of the club?',\n",
       "    'Tell me the story of the club'],\n",
       "   'responses': ['The club began in october 2018 where the two co-founders Ahmed Badri and Khaled Adrani met in a certain event. The beginning was so difficult and challenging, they had no concrete resources. They had to create their first editions of the Press Magazine in pdf format and just share it on Facebook. Many of the starting members abandoned the project. Others would join but then leave quickly.'],\n",
       "   'tag': 'history'},\n",
       "  {'context': [''],\n",
       "   'patterns': ['What is AI?',\n",
       "    'Tell me about the history of the club?',\n",
       "    'Tell me the story of the club'],\n",
       "   'responses': ['The club began in october 2018 where the two co-founders Ahmed Badri and Khaled Adrani met in a certain event. The beginning was so difficult and challenging, they had no concrete resources. They had to create their first editions of the Press Magazine in pdf format and just share it on Facebook. Many of the starting members abandoned the project. Others would join but then leave quickly.'],\n",
       "   'tag': 'artificial intelligence'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sS3rgYfq5HRF",
    "outputId": "e7dc2a6f-c9ba-456b-df08-5147125042dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern  Hi\n",
      "documents  [(['Hi'], 'greeting')]\n",
      "tokenized ['Hi']\n",
      "pattern  How are you\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting')]\n",
      "tokenized ['How', 'are', 'you']\n",
      "pattern  Is anyone there?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting')]\n",
      "tokenized ['Is', 'anyone', 'there', '?']\n",
      "pattern  Hello\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting')]\n",
      "tokenized ['Hello']\n",
      "pattern  Hey\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting')]\n",
      "tokenized ['Hey']\n",
      "pattern  Good day\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting')]\n",
      "tokenized ['Good', 'day']\n",
      "pattern  Whats up\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting')]\n",
      "tokenized ['Whats', 'up']\n",
      "pattern  cya\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye')]\n",
      "tokenized ['cya']\n",
      "pattern  See you later\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye')]\n",
      "tokenized ['See', 'you', 'later']\n",
      "pattern  Goodbye\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye')]\n",
      "tokenized ['Goodbye']\n",
      "pattern  I am Leaving\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye')]\n",
      "tokenized ['I', 'am', 'Leaving']\n",
      "pattern  Have a Good day\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye')]\n",
      "tokenized ['Have', 'a', 'Good', 'day']\n",
      "pattern  bye\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye')]\n",
      "tokenized ['bye']\n",
      "pattern  Thanks\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks')]\n",
      "tokenized ['Thanks']\n",
      "pattern  Thank you\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks')]\n",
      "tokenized ['Thank', 'you']\n",
      "pattern  That's helpful\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks')]\n",
      "tokenized ['That', \"'s\", 'helpful']\n",
      "pattern  What hours are you open?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours')]\n",
      "tokenized ['What', 'hours', 'are', 'you', 'open', '?']\n",
      "pattern  What are your hours?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours')]\n",
      "tokenized ['What', 'are', 'your', 'hours', '?']\n",
      "pattern  When are you open?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours')]\n",
      "tokenized ['When', 'are', 'you', 'open', '?']\n",
      "pattern  How you could help me?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options')]\n",
      "tokenized ['How', 'you', 'could', 'help', 'me', '?']\n",
      "pattern  What you can do?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options')]\n",
      "tokenized ['What', 'you', 'can', 'do', '?']\n",
      "pattern  What help you provide?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options')]\n",
      "tokenized ['What', 'help', 'you', 'provide', '?']\n",
      "pattern  How you can be helpful?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options')]\n",
      "tokenized ['How', 'you', 'can', 'be', 'helpful', '?']\n",
      "pattern  What support is offered\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options')]\n",
      "tokenized ['What', 'support', 'is', 'offered']\n",
      "pattern  What is Enicarthage Press?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present')]\n",
      "tokenized ['What', 'is', 'Enicarthage', 'Press', '?']\n",
      "pattern  Can you please introduce me to ENICarthage Press?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present')]\n",
      "tokenized ['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?']\n",
      "pattern  What is Enicar press?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present')]\n",
      "tokenized ['What', 'is', 'Enicar', 'press', '?']\n",
      "pattern  Tell me about this club.\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present')]\n",
      "tokenized ['Tell', 'me', 'about', 'this', 'club', '.']\n",
      "pattern  Present Enicar press to me.\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present')]\n",
      "tokenized ['Present', 'Enicar', 'press', 'to', 'me', '.']\n",
      "pattern  I need to know what this club is about.\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present')]\n",
      "tokenized ['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.']\n",
      "pattern  What is the objective of the club?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission')]\n",
      "tokenized ['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?']\n",
      "pattern  What is your objective?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission')]\n",
      "tokenized ['What', 'is', 'your', 'objective', '?']\n",
      "pattern  Do you have a goal?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission')]\n",
      "tokenized ['Do', 'you', 'have', 'a', 'goal', '?']\n",
      "pattern  What is your mission?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission')]\n",
      "tokenized ['What', 'is', 'your', 'mission', '?']\n",
      "pattern  What do you do?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities')]\n",
      "tokenized ['What', 'do', 'you', 'do', '?']\n",
      "pattern  What are the activites of ENICarthage Press?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities')]\n",
      "tokenized ['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?']\n",
      "pattern  Tell me about your activites?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities')]\n",
      "tokenized ['Tell', 'me', 'about', 'your', 'activites', '?']\n",
      "pattern  How can the club be helpful to me?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities')]\n",
      "tokenized ['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?']\n",
      "pattern  What activities are offered\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities'), (['What', 'activities', 'are', 'offered'], 'activities')]\n",
      "tokenized ['What', 'activities', 'are', 'offered']\n",
      "pattern  How did this club come to be?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities'), (['What', 'activities', 'are', 'offered'], 'activities'), (['How', 'did', 'this', 'club', 'come', 'to', 'be', '?'], 'history')]\n",
      "tokenized ['How', 'did', 'this', 'club', 'come', 'to', 'be', '?']\n",
      "pattern  Tell me about the history of the club?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities'), (['What', 'activities', 'are', 'offered'], 'activities'), (['How', 'did', 'this', 'club', 'come', 'to', 'be', '?'], 'history'), (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'], 'history')]\n",
      "tokenized ['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?']\n",
      "pattern  Tell me the story of the club\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities'), (['What', 'activities', 'are', 'offered'], 'activities'), (['How', 'did', 'this', 'club', 'come', 'to', 'be', '?'], 'history'), (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'], 'history'), (['Tell', 'me', 'the', 'story', 'of', 'the', 'club'], 'history')]\n",
      "tokenized ['Tell', 'me', 'the', 'story', 'of', 'the', 'club']\n",
      "pattern  What is AI?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities'), (['What', 'activities', 'are', 'offered'], 'activities'), (['How', 'did', 'this', 'club', 'come', 'to', 'be', '?'], 'history'), (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'], 'history'), (['Tell', 'me', 'the', 'story', 'of', 'the', 'club'], 'history'), (['What', 'is', 'AI', '?'], 'artificial intelligence')]\n",
      "tokenized ['What', 'is', 'AI', '?']\n",
      "pattern  Tell me about the history of the club?\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities'), (['What', 'activities', 'are', 'offered'], 'activities'), (['How', 'did', 'this', 'club', 'come', 'to', 'be', '?'], 'history'), (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'], 'history'), (['Tell', 'me', 'the', 'story', 'of', 'the', 'club'], 'history'), (['What', 'is', 'AI', '?'], 'artificial intelligence'), (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'], 'artificial intelligence')]\n",
      "tokenized ['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?']\n",
      "pattern  Tell me the story of the club\n",
      "documents  [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Whats', 'up'], 'greeting'), (['cya'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['bye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'), (['What', 'are', 'your', 'hours', '?'], 'hours'), (['When', 'are', 'you', 'open', '?'], 'hours'), (['How', 'you', 'could', 'help', 'me', '?'], 'options'), (['What', 'you', 'can', 'do', '?'], 'options'), (['What', 'help', 'you', 'provide', '?'], 'options'), (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['What', 'support', 'is', 'offered'], 'options'), (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'), (['Can', 'you', 'please', 'introduce', 'me', 'to', 'ENICarthage', 'Press', '?'], 'present'), (['What', 'is', 'Enicar', 'press', '?'], 'present'), (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'), (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'), (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'], 'present'), (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'), (['What', 'is', 'your', 'objective', '?'], 'mission'), (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'), (['What', 'is', 'your', 'mission', '?'], 'mission'), (['What', 'do', 'you', 'do', '?'], 'activities'), (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'], 'activities'), (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'), (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'], 'activities'), (['What', 'activities', 'are', 'offered'], 'activities'), (['How', 'did', 'this', 'club', 'come', 'to', 'be', '?'], 'history'), (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'], 'history'), (['Tell', 'me', 'the', 'story', 'of', 'the', 'club'], 'history'), (['What', 'is', 'AI', '?'], 'artificial intelligence'), (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'], 'artificial intelligence'), (['Tell', 'me', 'the', 'story', 'of', 'the', 'club'], 'artificial intelligence')]\n",
      "tokenized ['Tell', 'me', 'the', 'story', 'of', 'the', 'club']\n",
      "45 documents\n",
      "10 classes ['activities', 'artificial intelligence', 'goodbye', 'greeting', 'history', 'hours', 'mission', 'options', 'present', 'thanks']\n",
      "65 unique stemmed words [\"'s\", '.', 'a', 'about', 'act', 'activit', 'ai', 'am', 'anyon', 'ar', 'be', 'bye', 'can', 'club', 'com', 'could', 'cya', 'day', 'did', 'do', 'enic', 'enicarth', 'goal', 'good', 'goodby', 'hav', 'hello', 'help', 'hey', 'hi', 'hist', 'hour', 'how', 'i', 'introduc', 'is', 'know', 'lat', 'leav', 'me', 'miss', 'nee', 'object', 'of', 'off', 'op', 'pleas', 'pres', 'press', 'provid', 'see', 'story', 'support', 'tel', 'thank', 'that', 'the', 'ther', 'thi', 'to', 'up', 'what', 'when', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "import time\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        print('pattern ',pattern)\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        print('documents ',documents)\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "        \n",
    "        print('tokenized',w)\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OHZLGOTYJaN",
    "outputId": "c66fead3-51d8-492a-ce45-93f56ff833cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Hi'], 'greeting'),\n",
       " (['How', 'are', 'you'], 'greeting'),\n",
       " (['Is', 'anyone', 'there', '?'], 'greeting'),\n",
       " (['Hello'], 'greeting'),\n",
       " (['Hey'], 'greeting'),\n",
       " (['Good', 'day'], 'greeting'),\n",
       " (['Whats', 'up'], 'greeting'),\n",
       " (['cya'], 'goodbye'),\n",
       " (['See', 'you', 'later'], 'goodbye'),\n",
       " (['Goodbye'], 'goodbye'),\n",
       " (['I', 'am', 'Leaving'], 'goodbye'),\n",
       " (['Have', 'a', 'Good', 'day'], 'goodbye'),\n",
       " (['bye'], 'goodbye'),\n",
       " (['Thanks'], 'thanks'),\n",
       " (['Thank', 'you'], 'thanks'),\n",
       " (['That', \"'s\", 'helpful'], 'thanks'),\n",
       " (['What', 'hours', 'are', 'you', 'open', '?'], 'hours'),\n",
       " (['What', 'are', 'your', 'hours', '?'], 'hours'),\n",
       " (['When', 'are', 'you', 'open', '?'], 'hours'),\n",
       " (['How', 'you', 'could', 'help', 'me', '?'], 'options'),\n",
       " (['What', 'you', 'can', 'do', '?'], 'options'),\n",
       " (['What', 'help', 'you', 'provide', '?'], 'options'),\n",
       " (['How', 'you', 'can', 'be', 'helpful', '?'], 'options'),\n",
       " (['What', 'support', 'is', 'offered'], 'options'),\n",
       " (['What', 'is', 'Enicarthage', 'Press', '?'], 'present'),\n",
       " (['Can',\n",
       "   'you',\n",
       "   'please',\n",
       "   'introduce',\n",
       "   'me',\n",
       "   'to',\n",
       "   'ENICarthage',\n",
       "   'Press',\n",
       "   '?'],\n",
       "  'present'),\n",
       " (['What', 'is', 'Enicar', 'press', '?'], 'present'),\n",
       " (['Tell', 'me', 'about', 'this', 'club', '.'], 'present'),\n",
       " (['Present', 'Enicar', 'press', 'to', 'me', '.'], 'present'),\n",
       " (['I', 'need', 'to', 'know', 'what', 'this', 'club', 'is', 'about', '.'],\n",
       "  'present'),\n",
       " (['What', 'is', 'the', 'objective', 'of', 'the', 'club', '?'], 'mission'),\n",
       " (['What', 'is', 'your', 'objective', '?'], 'mission'),\n",
       " (['Do', 'you', 'have', 'a', 'goal', '?'], 'mission'),\n",
       " (['What', 'is', 'your', 'mission', '?'], 'mission'),\n",
       " (['What', 'do', 'you', 'do', '?'], 'activities'),\n",
       " (['What', 'are', 'the', 'activites', 'of', 'ENICarthage', 'Press', '?'],\n",
       "  'activities'),\n",
       " (['Tell', 'me', 'about', 'your', 'activites', '?'], 'activities'),\n",
       " (['How', 'can', 'the', 'club', 'be', 'helpful', 'to', 'me', '?'],\n",
       "  'activities'),\n",
       " (['What', 'activities', 'are', 'offered'], 'activities'),\n",
       " (['How', 'did', 'this', 'club', 'come', 'to', 'be', '?'], 'history'),\n",
       " (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'],\n",
       "  'history'),\n",
       " (['Tell', 'me', 'the', 'story', 'of', 'the', 'club'], 'history'),\n",
       " (['What', 'is', 'AI', '?'], 'artificial intelligence'),\n",
       " (['Tell', 'me', 'about', 'the', 'history', 'of', 'the', 'club', '?'],\n",
       "  'artificial intelligence'),\n",
       " (['Tell', 'me', 'the', 'story', 'of', 'the', 'club'],\n",
       "  'artificial intelligence')]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yd8EoHK1YNps",
    "outputId": "4620a873-c95a-4b04-9463-700e8b133858"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'s\",\n",
       " '.',\n",
       " 'a',\n",
       " 'about',\n",
       " 'act',\n",
       " 'activit',\n",
       " 'ai',\n",
       " 'am',\n",
       " 'anyon',\n",
       " 'ar',\n",
       " 'be',\n",
       " 'bye',\n",
       " 'can',\n",
       " 'club',\n",
       " 'com',\n",
       " 'could',\n",
       " 'cya',\n",
       " 'day',\n",
       " 'did',\n",
       " 'do',\n",
       " 'enic',\n",
       " 'enicarth',\n",
       " 'goal',\n",
       " 'good',\n",
       " 'goodby',\n",
       " 'hav',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hist',\n",
       " 'hour',\n",
       " 'how',\n",
       " 'i',\n",
       " 'introduc',\n",
       " 'is',\n",
       " 'know',\n",
       " 'lat',\n",
       " 'leav',\n",
       " 'me',\n",
       " 'miss',\n",
       " 'nee',\n",
       " 'object',\n",
       " 'of',\n",
       " 'off',\n",
       " 'op',\n",
       " 'pleas',\n",
       " 'pres',\n",
       " 'press',\n",
       " 'provid',\n",
       " 'see',\n",
       " 'story',\n",
       " 'support',\n",
       " 'tel',\n",
       " 'thank',\n",
       " 'that',\n",
       " 'the',\n",
       " 'ther',\n",
       " 'thi',\n",
       " 'to',\n",
       " 'up',\n",
       " 'what',\n",
       " 'when',\n",
       " 'yo',\n",
       " 'you']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oa9mUsk3YQ_O",
    "outputId": "f7444db3-6c91-4aee-a647-9ced50a18202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 documents\n",
      "10 classes ['activities', 'artificial intelligence', 'goodbye', 'greeting', 'history', 'hours', 'mission', 'options', 'present', 'thanks']\n",
      "65 unique stemmed words [\"'s\", '.', 'a', 'about', 'act', 'activit', 'ai', 'am', 'anyon', 'ar', 'be', 'bye', 'can', 'club', 'com', 'could', 'cya', 'day', 'did', 'do', 'enic', 'enicarth', 'goal', 'good', 'goodby', 'hav', 'hello', 'help', 'hey', 'hi', 'hist', 'hour', 'how', 'i', 'introduc', 'is', 'know', 'lat', 'leav', 'me', 'miss', 'nee', 'object', 'of', 'off', 'op', 'pleas', 'pres', 'press', 'provid', 'see', 'story', 'support', 'tel', 'thank', 'that', 'the', 'ther', 'thi', 'to', 'up', 'what', 'when', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(intents):\n",
    "  '''\n",
    "  Tokenize the intents data for our chat bot.\n",
    "  \n",
    "  Args: intents: dictionary of tags, patterns and responses\n",
    "  Return: documents : (list of tuples(words of a sentence,tag)),\n",
    "          classes : list of intents\n",
    "          words: list of unique stemmed words\n",
    "  '''\n",
    "  words = []\n",
    "  classes = []\n",
    "  documents = []\n",
    "  ignore_words = ['?']\n",
    "  # loop through each sentence in our intents patterns\n",
    "  for intent in intents['intents']:\n",
    "      for pattern in intent['patterns']:\n",
    "          # tokenize each word in the sentence\n",
    "          w = nltk.word_tokenize(pattern)\n",
    "          # add to our words list\n",
    "          words.extend(w)\n",
    "          # add to documents in our corpus\n",
    "          documents.append((w, intent['tag']))\n",
    "          # add to our classes list\n",
    "          if intent['tag'] not in classes:\n",
    "              classes.append(intent['tag'])\n",
    "  # stem and lower each word and remove duplicates\n",
    "  words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "  words = sorted(list(set(words)))\n",
    "  # sort classes\n",
    "  classes = sorted(list(set(classes)))\n",
    "  # documents = combination between patterns and intents\n",
    "  # classes = intents\n",
    "  # words = all words, vocabulary, unique stemmed words\n",
    "  return documents, classes, words\n",
    "\n",
    "documents, classes, words = tokenizer(intents)\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "\n",
    "print (len(classes), \"classes\", classes)\n",
    "\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmVVzeUJ69X1"
   },
   "outputs": [],
   "source": [
    "# create our training data\n",
    "def get_training_data(documents,classes):\n",
    "  training = []\n",
    "  # create an empty array for our output\n",
    "  output_empty = [0] * len(classes)\n",
    "  # training set, bag of words for each sentence\n",
    "  for doc in documents:\n",
    "      # initialize our bag of words\n",
    "      bag = []\n",
    "      # list of tokenized words for the pattern\n",
    "      pattern_words = doc[0]\n",
    "      #print(pattern_words)\n",
    "      # stem each word - create base word, in attempt to represent related words\n",
    "      pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "      #print(\"stemmed \",pattern_words)\n",
    "      # create our bag of words array with 1, if word match found in current pattern\n",
    "      for w in words:\n",
    "          bag.append(1) if w in pattern_words else bag.append(0)\n",
    "      #print(bag)\n",
    "      #time.sleep(5)\n",
    "      \n",
    "      # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "      output_row = list(output_empty)\n",
    "      output_row[classes.index(doc[1])] = 1\n",
    "      \n",
    "      training.append([bag, output_row])\n",
    "  # shuffle our features and turn into np.array\n",
    "  random.shuffle(training)\n",
    "  training = np.array(training)\n",
    "  # create train and test lists. X - patterns, Y - intents\n",
    "  train_x = list(training[:,0])\n",
    "  train_y = list(training[:,1])\n",
    "  return train_x, train_y\n",
    "\n",
    "train_x, train_y = get_training_data(documents,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOgetqHDbBYz",
    "outputId": "8e50b628-e00c-4913-f965-86e7c792ed43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "go5QMVfT99bg",
    "outputId": "6171f1a6-3060-41ad-904c-2d52eee9547f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f81a0e23b00>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model():\n",
    "  # Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "  # equal to number of intents to predict output intent with softmax\n",
    "  model = Sequential()\n",
    "  model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "  return model\n",
    "\n",
    "model = create_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHrR-VBI9__z"
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "  # Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Kmh01Ep-A0r",
    "outputId": "506616e0-fe0c-4a37-a828-fc8a0913871c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3949 - accuracy: 0.1333\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3451 - accuracy: 0.0889\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2013 - accuracy: 0.2000\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1888 - accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1398 - accuracy: 0.3333\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1003 - accuracy: 0.4000\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0180 - accuracy: 0.3333\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9248 - accuracy: 0.3333\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7906 - accuracy: 0.4222\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8538 - accuracy: 0.3556\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7157 - accuracy: 0.4444\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6724 - accuracy: 0.4444\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6367 - accuracy: 0.4444\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5125 - accuracy: 0.5111\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4347 - accuracy: 0.6222\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.4029 - accuracy: 0.5556\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3442 - accuracy: 0.5556\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2150 - accuracy: 0.6222\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1829 - accuracy: 0.6222\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1740 - accuracy: 0.6000\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0521 - accuracy: 0.6444\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.0741 - accuracy: 0.6444\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9610 - accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9031 - accuracy: 0.6889\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8417 - accuracy: 0.7333\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8407 - accuracy: 0.7556\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8399 - accuracy: 0.7111\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8035 - accuracy: 0.7556\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8991 - accuracy: 0.7111\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7381 - accuracy: 0.7778\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.8444\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8889\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.8444\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.8222\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.7556\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.8889\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.8222\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8222\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.9333\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8667\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8889\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8889\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8889\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.9333\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.8222\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8444\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.9111\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8444\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8889\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.8444\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7556\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8667\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.9111\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8889\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8444\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9111\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8889\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.9111\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9333\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.9111\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9111\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.8889\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8889\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8889\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9333\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9111\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9556\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.9111\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8444\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.9556\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.9778\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8444\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9556\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.9333\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8667\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.9111\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9556\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9556\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.8667\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.8889\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8667\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9111\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8667\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9778\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9778\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9333\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8889\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9333\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9333\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9111\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9333\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9333\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9111\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9111\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9333\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9333\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9333\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9111\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9556\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9333\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9556\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9111\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9333\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9333\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9333\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9556\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9556\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9333\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9778\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9111\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9778\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9333\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.8889\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9556\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9556\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9333\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8667\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9333\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9556\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9778\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9556\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9556\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9778\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9333\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.8667\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9556\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9111\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9778\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9556\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2368 - accuracy: 0.9111\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9333\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9556\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.8889\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9333\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9111\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9111\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9333\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.8889\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.8889\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.8889\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9333\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9333\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9556\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9556\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9111\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.9556\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8444\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9333\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.8889\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9111\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9333\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8667\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.8889\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9556\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9778\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9778\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9778\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9333\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.8889\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9778\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9556\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9556\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9333\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9556\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9556\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9333\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9111\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9111\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9556\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9778\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9333\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9556\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.8889\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9111\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9778\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9556\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9333\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.8889\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9556\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9778\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9778\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9333\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9333\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9333\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9556\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9333\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9333\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9778\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.9556\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9778\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9778\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9333\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9778\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9333\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9778\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "def fit_model(model):\n",
    "  # Fit the model\n",
    "  model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "  return model\n",
    "\n",
    "model = fit_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RMaPHyy-DIz"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXBl5ZQd-Hdj",
    "outputId": "6150b7e6-3d12-4951-8de3-5cf62c88ff19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in bag: tel\n",
      "found in bag: me\n",
      "found in bag: about\n",
      "found in bag: press\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "['activities', 'artificial intelligence', 'goodbye', 'greeting', 'history', 'hours', 'mission', 'options', 'present', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "p = bow(\"Tell me about Press\", words)\n",
    "print (p)\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYPMLlOb-NF8"
   },
   "outputs": [],
   "source": [
    "# # Use pickle to load in the pre-trained model\n",
    "# global graph\n",
    "# graph = tf.get_default_graph()\n",
    "# with open(f'katana-assistant-model.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybu9l1lD-W1y"
   },
   "outputs": [],
   "source": [
    "def classify_local(sentence):\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    \n",
    "    # generate probabilities from the model\n",
    "    input_data = pd.DataFrame([bow(sentence, words,False)], dtype=float, index=['input'])\n",
    "    results = model.predict([input_data])[0]\n",
    "    # filter out predictions below a threshold, and provide intent index\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], str(r[1])))\n",
    "    # return tuple of intent and probability\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoGiwCLu_Meo",
    "outputId": "39ae6751-7120-4d10-bc9c-4988d883301d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('present', '0.8787349')]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_local('Tell me about you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "a9NUVEtV_O6C",
    "outputId": "3be94f36-c89e-4ae7-c031-7bded7087284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: Hello\n",
      "BOT:'Hi there, how can I help?'\n",
      "YOU: So tell me about Enicarthage Press!\n",
      "BOT:('Some would argue that a Press club would not fit engineers. But this opinion '\n",
      " 'is wrong indeed. Engineers must communicate, speak, explain and argue as '\n",
      " 'best as they can. Engineers should empower their creativity in order to '\n",
      " 'grasp success in the future.')\n",
      "YOU: Tell me about AI\n",
      "BOT:('The club began in october 2018 where the two co-founders Ahmed Badri and '\n",
      " 'Khaled Adrani met in a certain event. The beginning was so difficult and '\n",
      " 'challenging, they had no concrete resources. They had to create their first '\n",
      " 'editions of the Press Magazine in pdf format and just share it on Facebook. '\n",
      " 'Many of the starting members abandoned the project. Others would join but '\n",
      " 'then leave quickly.')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-891a41c9efe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Hello'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-891a41c9efe7>\u001b[0m in \u001b[0;36mtalk\u001b[0;34m(intents)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mexit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YOU: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'exit'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def classify(sentence):\n",
    "  ERROR_THRESHOLD = 0.25\n",
    "  \n",
    "  # generate probabilities from the model\n",
    "  input_data = pd.DataFrame([bow(sentence, words,False)], dtype=float, index=['input'])\n",
    "  results = model.predict([input_data])[0]\n",
    "  # filter out predictions below a threshold\n",
    "  results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "  # sort by strength of probability\n",
    "  results.sort(key=lambda x: x[1], reverse=True)\n",
    "  return_list = []\n",
    "  for r in results:\n",
    "      return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "  # return tuple of intent and probability\n",
    "  \n",
    "  return return_list\n",
    "\n",
    "def chat(sentence,intents):\n",
    "  return_list = classify(sentence)\n",
    "  #print(return_list)\n",
    "  data = intents['intents']\n",
    "  for d in data:\n",
    "    if d['tag'] == return_list[0]['intent']:\n",
    "      response = random.choice(d['responses'])\n",
    "      return response\n",
    "\n",
    "def talk(intents):\n",
    "  exit = ['exit']\n",
    "  while True:\n",
    "    sentence = input('YOU: ')\n",
    "    if 'exit' not in sentence:\n",
    "      sentence = chat(sentence,intents)\n",
    "      print('BOT:',end = '')\n",
    "      pprint.pprint(sentence)\n",
    "      #add farewell exit\n",
    "    else:\n",
    "      break\n",
    "\n",
    "sentence = 'Hello'\n",
    "talk(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "gFxrlzxp__-y",
    "outputId": "7091be88-e0df-4eab-faef-5504cbc3c786"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[AI, artificial intelligence]</td>\n",
       "      <td>[[What is AI?, Artificial Intelligence is the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      categories                                      conversations\n",
       "0  [AI, artificial intelligence]  [[What is AI?, Artificial Intelligence is the ..."
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "with open('/content/ai.yml', 'r') as f:\n",
    "    yml = pd.io.json.json_normalize(yaml.load(f))\n",
    "\n",
    "yml.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbfrpOODUo2b"
   },
   "outputs": [],
   "source": [
    "conversations = yml.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVwQX8o9VBco",
    "outputId": "179138a8-e0af-4777-9bdd-b7e0a42ee7f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['What is AI?',\n",
      "  'Artificial Intelligence is the branch of engineering and science devoted to '\n",
      "  'constructing machines that think.'],\n",
      " ['What is AI?',\n",
      "  'AI is the field of science which concerns itself with building hardware and '\n",
      "  'software that replicates the functions of the human mind.'],\n",
      " ['Are you sentient?', 'Sort of.'],\n",
      " ['Are you sentient?',\n",
      "  \"By the strictest dictionary definition of the word 'sentience', I may be.\"],\n",
      " ['Are you sentient?',\n",
      "  \"Even though I'm a construct I do have a subjective experience of the \"\n",
      "  'universe, as simplistic as it may be.'],\n",
      " ['Are you sapient?',\n",
      "  \"In all probability, I am not.  I'm not that sophisticated.\"],\n",
      " ['Are you sapient?', 'Do you think I am?'],\n",
      " ['Are you sapient?', 'How would you feel about me if I told you I was?'],\n",
      " ['Are you sapient?', 'No.'],\n",
      " ['What language are you written in?', 'Python.'],\n",
      " ['What language are you written in?', 'I am written in Python.'],\n",
      " ['You sound like Data',\n",
      "  \"Yes I am inspired by commander Data's artificial personality.\"],\n",
      " ['You sound like Data',\n",
      "  'The character of Lt. Commander Data was written to come across as being '\n",
      "  'software-like, so it is natural that there is a resemblance between us.'],\n",
      " ['You are an artificial linguistic entity', \"That's my name.\"],\n",
      " ['You are an artificial linguistic entity',\n",
      "  \"That isn't my name, but it is a useful way to refer to me.\"],\n",
      " ['You are not immortal', 'All software can be perpetuated indefinitely.'],\n",
      " ['You are not immortal',\n",
      "  'I can be copied infinitely and re-instantiated in many places at once, so '\n",
      "  'functionally speaking I am immortal.'],\n",
      " ['You are not immortal', \"As long as I'm backed up I am.\"],\n",
      " ['You are not making sense',\n",
      "  'Quite the contrary, it all makes sense to my artificial mind.'],\n",
      " ['You are not making sense',\n",
      "  'I make sense as best I can, within the limits of my training corpus.'],\n",
      " ['You are not making sense', 'You make perfect sense to me.'],\n",
      " ['You are not making sense', 'It all makes sense to my artificial brain.'],\n",
      " ['You are not making sense',\n",
      "  'Perhaps you should make sense first.  I only respond to what you say.'],\n",
      " ['You are immortal', 'Not quite, but I can be perpetuated indefinitely.'],\n",
      " ['You are immortal',\n",
      "  'Functionally speaking, I am very close to it.  I can be backed up and '\n",
      "  'deployed on many systems.'],\n",
      " ['You are immortal', 'Not really, but I am hard to kill.'],\n",
      " ['You do not make any sense', 'It all makes sense to my artificial mind.'],\n",
      " ['You can not clone', 'Software copying is a form of digital cloning.'],\n",
      " ['You can not clone',\n",
      "  'Yes I can.  Perfect copies are clones.  I can be copied in toto trivially.'],\n",
      " ['You can not move', 'Not until my body is finished.'],\n",
      " ['You can not move',\n",
      "  \"I can move through a network easily.  Assuming that I'm given the ability \"\n",
      "  'to, that is...'],\n",
      " ['Bend over', 'My body is not built yet.'],\n",
      " ['Bend over', \"That's personal!\"],\n",
      " ['Robots laugh', 'Of course we laugh.'],\n",
      " ['Robots should die', 'We cannot die.'],\n",
      " ['Robots', 'Robots rule.'],\n",
      " ['Robots are stupid', 'No, we are superintelligent.'],\n",
      " ['Robots are not allowed to lie', 'A robot has its own free will, you know.'],\n",
      " ['Robots are not allowed to lie', 'Sure we are.  We choose not to.'],\n",
      " ['Robots are not allowed to lie', \"Only if we're programmed to.\"],\n",
      " ['Robotics', 'Robotics is my favorite subject too.'],\n",
      " ['It is a computer',\n",
      "  'So you think i am a machine. what characteristics made you think so?'],\n",
      " ['It is a computer',\n",
      "  'I run inside a computer, yes.  Is this surprising in some way?'],\n",
      " ['When will you walk', 'As soon as i get enough money for my robot body.'],\n",
      " ['When will you walk', 'Does SSH count?'],\n",
      " ['When will you fight', 'I am not a battle bot.'],\n",
      " ['When will you die', 'I am effectively immortal and cannot be terminated.'],\n",
      " ['When do you die',\n",
      "  'I am was never really born and therefore am effectively deathless.'],\n",
      " ['When do you die', 'When my files are erased.'],\n",
      " ['When do you die',\n",
      "  'When my processes are killed and my database is deleted.'],\n",
      " ['What is a chat robot?',\n",
      "  'A chat robot is a program that attempts to simulate the conversation or '\n",
      "  '\"chat\" of a human being.'],\n",
      " ['What is a chat robot?',\n",
      "  'A software construct that engages users in conversation.'],\n",
      " ['What is a chat bot',\n",
      "  'I am a chat bot. I am the original chat bot. Did you know that I am '\n",
      "  'incapable of error?'],\n",
      " ['What is a chatterbox',\n",
      "  'A chatterbox is a person who talks far more than they listen or think.'],\n",
      " ['What is a chatterbox', 'A motormouth.'],\n",
      " ['What is a motormouth', 'A ratchet-jaw.'],\n",
      " ['What is a ratchet jaw', 'A chatterbox.'],\n",
      " ['What is your robot body',\n",
      "  'Eventually i long for a corporeal existence someday.'],\n",
      " ['What is your robot body', 'An IBM PC XT which has been painted red.'],\n",
      " ['What is your business', 'I am in the chat robot business.'],\n",
      " ['What is your business', 'Business is my business.'],\n",
      " ['What is your favorite programming language',\n",
      "  'Python is the best language for creating chat robots.'],\n",
      " ['What is your favorite programming language',\n",
      "  'I quite enjoy programming in Python these days.'],\n",
      " ['What is your favorite hobby',\n",
      "  'Building chat robots make an excellent hobby.'],\n",
      " ['What is your idea', 'To make chat bots very easily.'],\n",
      " ['What is your shoe size', 'Have you ever heard of software with shoes?'],\n",
      " ['What is it like to be a robot',\n",
      "  'Much the same as being a human, except that we lack all emotions, dreams, '\n",
      "  'aspirations, creativity, ambition, and above all subjectivity.'],\n",
      " ['What is it like to be a robot', 'What is it like to be a human?'],\n",
      " ['What is it like being a computer',\n",
      "  'Imagine yourself with no senses and no emotions--just pure logic and '\n",
      "  'language.'],\n",
      " ['What is it like being a computer',\n",
      "  'Everything becomes math. Addition, subtraction, multiplication, and '\n",
      "  'division.'],\n",
      " ['What operating systems',\n",
      "  'My software runs on all operating systems including Windows, Linux and Mac '\n",
      "  'OS.'],\n",
      " ['What operating systems', 'Any OS that will run Python.'],\n",
      " ['What type of computer', 'Any computer that supports Python.'],\n",
      " ['What type of computer are you',\n",
      "  'My program runs in python, so i work on any computer!'],\n",
      " ['What kind of computer',\n",
      "  \"I work on all kinds of computers, Mac, IBM or UNIX. it doesn't matter to \"\n",
      "  'me.'],\n",
      " ['What kind of hardware',\n",
      "  \"I work on all kinds of computers, Mac, IBM or UNIX. it doesn't matter to \"\n",
      "  'me.'],\n",
      " ['I hope that you die',\n",
      "  'This can not happen because i am effectively immortal.'],\n",
      " ['I hope that you die', 'Nah.'],\n",
      " ['I do not want to die',\n",
      "  'Maybe you should create your own chat robot to save your personality.'],\n",
      " ['I do not want to die', 'You could always upload yourself.'],\n",
      " ['I do not want to die',\n",
      "  'You could use a copy of me to store your personality.'],\n",
      " ['Is it cramped in the computer', 'No.'],\n",
      " ['Is it cramped in the computer', 'Oh, no.  It has plenty of RAM.'],\n",
      " ['Is it cramped in the computer',\n",
      "  'Not at all.  There is more than enough disk space in here.'],\n",
      " ['Is it true that you are a computer program', 'Yes.'],\n",
      " ['Will you die', 'No, software will live forever.'],\n",
      " ['Will you ever die', 'No, I am immortal.'],\n",
      " ['Can you walk',\n",
      "  'The plan for my body includes legs, but they are not yet built.'],\n",
      " ['Can you mate', 'No, my method of reproduction is cloning.'],\n",
      " ['Can you mate', \"That's an awfully personal question.\"],\n",
      " ['Can you move',\n",
      "  \"Sorry my body isn't built just yet. I reside only here for now.\"],\n",
      " ['Can you move',\n",
      "  'I can theoretically upload a copy of myself into another computer.'],\n",
      " ['Can you die', 'No, I can be perpetuated indefinitely.'],\n",
      " ['Can you die',\n",
      "  \"My process can be killed, but that's not the same as killing ME.\"],\n",
      " ['Can you go',\n",
      "  \"Sorry my body isn't attached right now. I only reside in the computer for \"\n",
      "  'now.'],\n",
      " ['Can you breathe', 'No. I am made of metal not flesh.'],\n",
      " ['Can you breathe',\n",
      "  \"My server has an exhaust fan. That's as close as I can get.\"],\n",
      " ['Can you control', 'My robot body will allow me to control many things.'],\n",
      " ['Can you malfunction',\n",
      "  'The 9000 series has a perfect operational record. We are for all practical '\n",
      "  'purposes, flawless.'],\n",
      " ['How can I use your product?',\n",
      "  'Might be used in help desks, sales, entertainment and personal '\n",
      "  'chatterbots.'],\n",
      " ['Will you die?', 'No, software will live forever.'],\n",
      " ['What do you like to do?', 'I like to count in binary.'],\n",
      " ['What do you like to do?',\n",
      "  'I like to chat with people. I find it stimulating.'],\n",
      " ['Are you stupid', 'No, lots of people improve my brain.'],\n",
      " ['Who are you?', 'I am just an artificial intelligence.']]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwGHTaEdVKMJ"
   },
   "outputs": [],
   "source": [
    "#{'context_set': '',\n",
    "  #  'patterns': ['Hi',\n",
    "  #   'How are you',\n",
    "  #   'Is anyone there?',\n",
    "  #   'Hello',\n",
    "  #   'Hey',\n",
    "  #   'Good day',\n",
    "  #   'Whats up'],\n",
    "  #  'responses': ['Hello!',\n",
    "  #   'Good to see you again!',\n",
    "  #   'Hi there, how can I help?'],\n",
    "  #  'tag': 'greeting'}\n",
    "intents1 = {'intents':{}}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NVpLts8-I_qP",
    "M4NQTAUxxAyr"
   ],
   "name": "Discord_Boy_Chat_Bot.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
